{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition face dataset into 8:2 training:test\n",
    "\n",
    "### Apply PCA on training data by use of eigenvectors and eigenvalues of covaraiance matrix S= (1/N)A(A^T)\n",
    "\n",
    "### Apply PCA using eigenvectors and eigenvalues of (1/N)(A^T)A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA source: Week 2 slides - Manifold Learning\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data = loadmat('face.mat')\n",
    "\n",
    "X = data['X'] # flat images dim (2576,520)\n",
    "# l = data['l'].flatten()  # image Labels (1,520)\n",
    "\n",
    "# Does a 8/2 split of dataset (8 images / 2 images of each person). Training data shuffled. \n",
    "def Q1_partition(data):\n",
    "    X = data['X'] # flat images dim (2576,520)\n",
    "    l = data['l'].flatten() \n",
    "    sets = [[], [], [], []]\n",
    "    for i in range(0, 520, 10):\n",
    "        im_train, im_test, l_train, l_test = train_test_split(X[:, i: i + 10].T, l[i: i + 10], test_size=0.2, random_state=42)\n",
    "        sets[0].append(im_train)    \n",
    "        sets[1].append(im_test)  \n",
    "        sets[2].append(l_train)    \n",
    "        sets[3].append(l_test)  \n",
    "\n",
    "    for i in range(4):\n",
    "        if i < 2:\n",
    "             sets[i] = np.array(sets[i]).reshape(-1, 2576)\n",
    "        else: \n",
    "            sets[i] = np.array(sets[i]).flatten()\n",
    "    \n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into five equal sets of 2 images per person x 52 people = 104 \n",
    "def Q2_partition(data, num_partitions):\n",
    "    X = data['X'] # flat images dim (2576,520)\n",
    "    t = [[] for _ in range(num_partitions)]\n",
    "    y = [[] for _ in range(num_partitions)]\n",
    "    \n",
    "    for i in range(0, 520, 10):\n",
    "        slice = X[:, i: i + 10].T\n",
    "        slice_l = l[i: i + 10] \n",
    "        for j in range(num_partitions):\n",
    "            t[j].append(slice[j*2:(j+1)*2])\n",
    "            y[j].append(slice_l[j*2:(j+1)*2])\n",
    "       \n",
    "    for i in range(num_partitions-1):\n",
    "        t[i] = np.array(t[i]).reshape(-1, 2576) # Also shuffle \n",
    "        # np.random.shuffle(t[i])\n",
    "        y[i] = np.array(y[i]).flatten()\n",
    "\n",
    "        indices = np.random.permutation(len(t[i]))\n",
    "        t[i] = t[i][indices]\n",
    "        y[i] = y[i][indices]\n",
    "\n",
    "\n",
    "    t[-1] = np.array(t[-1]).reshape(-1, 2576)\n",
    "    y[-1] = np.array(y[-1]) \n",
    "\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, label):\n",
    "    # X[:, image_index]\n",
    "    image_height, image_width = 46, 56 \n",
    "    image = image.reshape((image_height, image_width)).T \n",
    "    # label = l[image_index]\n",
    "\n",
    "    plt.imshow(image, cmap='gray', aspect='auto')\n",
    "    plt.title(f\"Face Image - Label: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # display_image(X_train[1:2].T, \"hey\")\n",
    "    # display_image(t1[i:i+1].T, \"Hey\")\n",
    "\n",
    "def get_sorted_eigen(M):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(M)\n",
    "    eigenvalues, eigenvectors = np.real(eigenvalues), np.real(eigenvectors)\n",
    "\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "\n",
    "    sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    return sorted_eigenvalues, sorted_eigenvectors\n",
    "\n",
    "# S = Covariance Matrix, A = mean centred data, N = #samples\n",
    "def my_PCA(batch, k = 100):\n",
    "    _, mean, S = process_batch(batch)\n",
    "    eigenvalues, eigenvectors = get_sorted_eigen(S)\n",
    "    # k = choose_principal_components(threshold, eigenvalues)\n",
    "    return eigenvalues[:k + 1], eigenvectors[:, :k + 1], mean\n",
    "\n",
    "def choose_principal_components(threshold, eigenvalues):\n",
    "    covariance_ratios = eigenvalues/np.sum(eigenvalues)\n",
    "    cum_var = 0\n",
    "    for k, ratio in enumerate(covariance_ratios):\n",
    "        cum_var += ratio\n",
    "        if cum_var >= threshold: return k \n",
    "\n",
    "def process_batch(batch):\n",
    "    mean = np.mean(batch, axis=0)\n",
    "    A = batch - mean\n",
    "    N = A.shape[1]\n",
    "    S = (1/N) * np.dot(A.T, A)\n",
    "    #print(f'S / mean shapes: {S.shape}/{mean.shape}')\n",
    "    return N, mean, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (52,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mQ2_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m batch \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m N, mean, S \u001b[38;5;241m=\u001b[39m process_batch(X_train)\n",
      "Cell \u001b[1;32mIn[88], line 17\u001b[0m, in \u001b[0;36mQ2_partition\u001b[1;34m(data, num_partitions)\u001b[0m\n\u001b[0;32m     15\u001b[0m t[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(t[i])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2576\u001b[39m) \u001b[38;5;66;03m# Also shuffle \u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# np.random.shuffle(t[i])\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m y[i] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     19\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(t[i]))\n\u001b[0;32m     20\u001b[0m t[i] \u001b[38;5;241m=\u001b[39m t[i][indices]\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (52,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "t = Q2_partition(data,5)\n",
    "batch = t[0]\n",
    "N, mean, S = process_batch(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_PCA(data, num_partitions = 5):\n",
    "    t = Q2_partition(data, num_partitions)\n",
    "    \n",
    "    N1, mu1, S1 = process_batch(t[0])\n",
    "\n",
    "    for batch in t[1:-1]:  # every batch except first (already initialized) and last (test)\n",
    "        N2, mu2, S2 = process_batch(batch)\n",
    "        print(batch.shape)\n",
    "\n",
    "        N3 = N1 + N2\n",
    "        mu3 = (N1*mu1 + N2*mu2)/N3\n",
    "        mu12 = mu1-mu2\n",
    "        term1 = (N1/N3) * S1\n",
    "        term2 = (N2/N3)*S2\n",
    "        term3 = (N1*N2)/(N3**2) * np.outer(mu12, mu12.T)  \n",
    "        S3 =  term1 + term2 + term3 \n",
    "\n",
    "        N1, mu1, S1 = N3, mu3, S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_reduced_representation(image, W, X_mean):\n",
    "    centered_image = image - X_mean  # Step 1: Center the image\n",
    "    Z = np.dot(centered_image, W)    # Step 2: Project onto principal components\n",
    "    return Z\n",
    "\n",
    "def reconstruct_image(Z, W, X_mean):\n",
    "    X_reconstructed = np.dot(Z, W.T) + X_mean  # Project back to original space\n",
    "    return X_reconstructed\n",
    "\n",
    "# Assuming `W`, `X_mean`, and `original_classifier` are already defined\n",
    "def test_reconstructed_accuracy(X_test, y_test, W, X_mean, original_classifier):\n",
    "    reconstructed_images = []\n",
    "    \n",
    "    # Reconstruct each test image after applying PCA\n",
    "    for image in X_test:\n",
    "        Z = get_reduced_representation(image, W, X_mean)  # Project to PCA space\n",
    "        reconstructed_image = reconstruct_image(Z, W, X_mean)  # Reconstruct\n",
    "        reconstructed_images.append(reconstructed_image)\n",
    "    \n",
    "    # Convert list to numpy array for classifier compatibility\n",
    "    reconstructed_images = np.array(reconstructed_images)\n",
    "    \n",
    "    # Get predictions on reconstructed images\n",
    "    y_pred = original_classifier.predict(reconstructed_images)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example function to train a classifier on the original data\n",
    "def train_classifier(X_train, y_train):\n",
    "    # Use a pipeline to standardize data before applying SVM\n",
    "    classifier = make_pipeline(StandardScaler(), SVC(kernel='linear', random_state=42))\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return classifier\n",
    "\n",
    "# Example usage\n",
    "original_classifier = train_classifier(X_train, l_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_comps: 50\n",
      "Accuracy on reconstructed images: 0.7788461538461539\n",
      "Accuracy : 0.7788461538461539\n",
      "Num_comps: 100\n",
      "Accuracy on reconstructed images: 0.7980769230769231\n",
      "Accuracy : 0.8173076923076923\n",
      "Num_comps: 200\n",
      "Accuracy on reconstructed images: 0.8269230769230769\n",
      "Accuracy : 0.8173076923076923\n",
      "Num_comps: 300\n",
      "Accuracy on reconstructed images: 0.8461538461538461\n",
      "Accuracy : 0.8461538461538461\n",
      "Num_comps: 400\n",
      "Accuracy on reconstructed images: 0.8461538461538461\n",
      "Accuracy : 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def get_principal_components(X_train, num_components):\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(X_train)  # Fit PCA on the training data\n",
    "    W = pca.components_.T  # Transpose to get shape [original_dim, num_components]\n",
    "    return W, pca  # Return W and the trained PCA model for further use\n",
    "\n",
    "for num_components in [50,100,200,300,400]:\n",
    "\n",
    "\n",
    "    print(f'Num_comps: {num_components}')\n",
    "    # They cannot possibly be the same since they have different dimensions. \n",
    "    [X_train, X_test, l_train, l_test] = Q1_partition(data)\n",
    "    ##### Look here FELIX - AAT: S = (1/N) A * A^T, ATA: S = (1/N) A^T * A  \n",
    "    eigenvalues_AAT, eigenvectors_AAT, mean_AAT = my_PCA(X_train, k=num_components)\n",
    "    # eigenvalues_ATA, eigenvectors_ATA, mean_ATA = PCA(X_train.T)\n",
    "    ##########\n",
    "\n",
    "\n",
    "    # Example usage\n",
    "    \n",
    "    W, pca_model = get_principal_components(X_train, num_components)\n",
    "\n",
    "    # Example usage\n",
    "    accuracy = test_reconstructed_accuracy(X_test, l_test, eigenvectors_AAT, mean_AAT, original_classifier)\n",
    "    print(\"Accuracy on reconstructed images:\", accuracy)\n",
    "    accuracy = test_reconstructed_accuracy(X_test, l_test, W, mean_AAT, original_classifier)\n",
    "    print(\"Accuracy :\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (52,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mincremental_PCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[62], line 2\u001b[0m, in \u001b[0;36mincremental_PCA\u001b[1;34m(data, num_partitions)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mincremental_PCA\u001b[39m(data, num_partitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mQ2_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_partitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     N1, mu1, S1 \u001b[38;5;241m=\u001b[39m process_batch(t[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m t[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:  \u001b[38;5;66;03m# every batch except first (already initialized) and last (test)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[31], line 17\u001b[0m, in \u001b[0;36mQ2_partition\u001b[1;34m(data, num_partitions)\u001b[0m\n\u001b[0;32m     15\u001b[0m t[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(t[i])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2576\u001b[39m) \u001b[38;5;66;03m# Also shuffle \u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# np.random.shuffle(t[i])\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m y[i] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     19\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;28mlen\u001b[39m(t[i]))\n\u001b[0;32m     20\u001b[0m t[i] \u001b[38;5;241m=\u001b[39m t[i][indices]\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (52,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "incremental_PCA(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
